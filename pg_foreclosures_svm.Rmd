---
title: "pg_foreclosure_svm"
author: "Paul Kiefer"
date: "2024-04-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
options(scipen=999)
##install.packages("ggrepel")
##install.packages('ggthemes')
##install.packages('gplots')
#install.packages('car')
##install.packages("glmnet")
##install.packages("neuralnet")
install.packages("keras")
library(tidyverse)
library(dplyr)
#Necessary for date parsing.
library(lubridate)
#Necessary for column name cleaning.
library(janitor)
#Eventually necessary for visualization
library(ggthemes)
#Necessary for Census API calls.
library(tidycensus)
#Eventually necessary for visualizations.
library(ggplot2)
library(gplots)
#Potentially necessary for cleaning.
library(ggrepel)
#Eventually necessary for visualizations.
library(tigris)
#Simple features.
library(sf)
#Eventually necessary for mapping.
library(ggmap)
#Needed for dividing into training and test sets.
library(caret)
#Needed for data pre-processing and evaluation
library(car)
#Needed for regularization
library(glmnet)
library(e1071) 
#Needed to build SVM model
library(neuralnet)
#Needed for neural networks
library(nnet)
#Needed to plot neural networks
```

Read in our dataset: 

```{r}
pg_foreclosures_per_tract <- read_csv("datasets/pg_foreclosures_per_tract.csv", guess_max=173)
```
First, we build an SVM using the continuous variable foreclosure_pc_2020.

```{r}
# Step 1: Data Preprocessing
# Set seed for reproducibility
set.seed(123)

# Randomly sample row indices for the training set
train_index <- sample(nrow(pg_foreclosures_per_tract), 0.8 * nrow(pg_foreclosures_per_tract))

# Create training and testing datasets
train_data <- pg_foreclosures_per_tract[train_index, ]
test_data <- pg_foreclosures_per_tract[-train_index, ]

# Step 2: Model Training
svm_model <- svm(foreclosure_pc_2020 ~ ., data = train_data, kernel = "linear")

# Step 3: Model Evaluation
# Predictions on test set
predictions <- predict(svm_model, test_data)

# Calculate evaluation metrics
mse <- mean((test_data$foreclosure_pc_2020 - predictions)^2)
rmse <- sqrt(mse)
rsquared <- cor(predictions, test_data$foreclosure_pc_2020)^2

# Print evaluation metrics
print(paste("Mean Squared Error (MSE):", mse))
print(paste("Root Mean Squared Error (RMSE):", rmse))
print(paste("R-squared (R²):", rsquared))
```

Next, we create a column called foreclosure_hi_med_low to the dataframe and test a version of the SVM that uses a classifier rather than a regression. 

```{r}
# Add a new column 'foreclosure_hi_med_low' to the dataframe
pg_foreclosures_per_tract$foreclosure_hi_med_low <- cut(pg_foreclosures_per_tract$foreclosure_pc_2020,
                                                        breaks = quantile(pg_foreclosures_per_tract$foreclosure_pc_2020, probs = c(0, 1/3, 2/3, 1)),
                                                        labels = c(1, 2, 3),
                                                        include.lowest = TRUE)

# Convert the new column to factor
pg_foreclosures_per_tract$foreclosure_hi_med_low <- as.factor(pg_foreclosures_per_tract$foreclosure_hi_med_low)

# Train-test split
set.seed(123)
train_index <- createDataPartition(pg_foreclosures_per_tract$foreclosure_hi_med_low, p = 0.8, list = FALSE)
train_data <- pg_foreclosures_per_tract[train_index, ]
test_data <- pg_foreclosures_per_tract[-train_index, ]

# Train SVM model for classification
svm_model_classification <- svm(foreclosure_hi_med_low ~ ., data = train_data, kernel = "linear")

# Predictions on test set
predictions_classification <- predict(svm_model_classification, test_data)

# Evaluate classification performance
confusionMatrix(predictions_classification, test_data$foreclosure_hi_med_low)
```

SVM Classification with RBF Kernel
```{r}
# Train SVM model with RBF kernel for classification
svm_model_rbf <- svm(foreclosure_hi_med_low ~ ., data = train_data, kernel = "radial")

# Predictions on test set
predictions_rbf <- predict(svm_model_rbf, test_data)

# Evaluate classification performance
confusionMatrix(predictions_rbf, test_data$foreclosure_hi_med_low)
```
SVM Model with Polynomial Kernel for Regression

```{r}
# Train SVM model with Polynomial kernel for regression
svm_model_poly <- svm(foreclosure_pc_2020 ~ ., data = train_data, kernel = "polynomial")

# Predictions on test set
predictions_poly <- predict(svm_model_poly, test_data)

# Calculate evaluation metrics (RMSE for regression)
rmse_poly <- sqrt(mean((test_data$foreclosure_pc_2020 - predictions_poly)^2))
print(paste("Root Mean Squared Error (RMSE) for Polynomial Kernel:", rmse_poly))
```
We can check the significance of that RMSE:
```{r}
# Calculate the range of foreclosures_pc_2020 values
min_value <- min(pg_foreclosures_per_tract$foreclosure_pc_2020)
max_value <- max(pg_foreclosures_per_tract$foreclosure_pc_2020)
range_values <- max_value - min_value

# Print the range
print(paste("Range of foreclosures_pc_2020 values:", range_values))

# Compare RMSE to the range of values
print(paste("Root Mean Squared Error (RMSE):", rmse_poly))
if (rmse_poly < range_values) {
  print("RMSE is relatively small compared to the range of foreclosures_pc_2020 values.")
} else {
  print("RMSE is relatively large compared to the range of foreclosures_pc_2020 values.")
}

# Additional assessment
# You can also consider comparing RMSE to the standard deviation of the target variable
standard_deviation <- sd(pg_foreclosures_per_tract$foreclosure_pc_2020)
print(paste("Standard Deviation of foreclosures_pc_2020 values:", standard_deviation))
if (rmse_poly < standard_deviation) {
  print("RMSE is relatively small compared to the standard deviation of foreclosures_pc_2020 values.")
} else {
  print("RMSE is relatively large compared to the standard deviation of foreclosures_pc_2020 values.")
}
```
```{r}
# Train SVM model with RBF kernel for regression
svm_model_rbf_regression <- svm(foreclosure_pc_2020 ~ ., data = train_data, kernel = "radial")

# Predictions on test set
predictions_rbf_regression <- predict(svm_model_rbf_regression, test_data)

# Calculate evaluation metrics (RMSE for regression)
rmse_rbf_regression <- sqrt(mean((test_data$foreclosure_pc_2020 - predictions_rbf_regression)^2))
print(paste("Root Mean Squared Error (RMSE) for RBF Kernel (Regression):", rmse_rbf_regression))
```

SVM classification model with Polynomial kernel;
```{r}
# Train-test split
set.seed(123)
train_index <- createDataPartition(pg_foreclosures_per_tract$foreclosure_pc_2020, p = 0.8, list = FALSE)
train_data <- pg_foreclosures_per_tract[train_index, ]
test_data <- pg_foreclosures_per_tract[-train_index, ]

# Add a new column 'foreclosure_hi_med_low' to the dataframe
train_data$foreclosure_hi_med_low <- cut(train_data$foreclosure_pc_2020,
                                         breaks = quantile(train_data$foreclosure_pc_2020, probs = c(0, 1/3, 2/3, 1)),
                                         labels = c(1, 2, 3),
                                         include.lowest = TRUE)

# Convert the new column to factor
train_data$foreclosure_hi_med_low <- as.factor(train_data$foreclosure_hi_med_low)

# Train SVM model with Polynomial kernel for classification
svm_model_poly_classification <- svm(foreclosure_hi_med_low ~ ., data = train_data, kernel = "polynomial")

# Predictions on test set
predictions_poly_classification <- predict(svm_model_poly_classification, test_data)

# Evaluate classification performance
confusionMatrix(predictions_poly_classification, test_data$foreclosure_hi_med_low)
```


Neural Networks:


Test Neural Networks:
  
```{r}
# Select the list of independent variables and the dependent variable
independent_variables <- c(
  "avg_bed", "tract_homevalue_2020", "tract_medage_2020", "tract_medincome_2020", 
  "tract_medincome_2010", "foreclosure_pc_2010", "pct_built_2020_later", 
  "pct_built_2010_2019", "pct_built_2000_2009", "pct_built_1990_1999", 
  "pct_built_1980_1989", "pct_built_1970_1979", "pct_built_pre_1960", 
  "pct_0_bd", "pct_1_bd", "pct_2_bd", "pct_3_bd", "pct_4_more_bd", 
  "poverty_2010", "poverty_2020", "nhwhite_2010", "nhwhite_2020", 
  "mortgaged_2010", "mortgaged_2015", "mortgaged_2020", "ownoccupied_2010", 
  "ownoccupied_2015", "ownoccupied_2020", "mortgage_change_2010_2015", 
  "mortgage_change_2015_2020", "mortgage_change_2010_2020", 
  "ownoccupied_change_2010_2015", "ownoccupied_change_2015_2020", 
  "ownoccupied_change_2010_2020", "poverty_change_2010_2020", 
  "nhwhite_change_2010_2020", "medincome_change_2010_2015", 
  "medincome_change_2015_2020", "medincome_change_2010_2020", "pop_change_pct"
)

min_max_scaling <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}

# Extract the selected columns from the dataframe
selected_data <- pg_foreclosures_per_tract[independent_variables]

# Normalize the selected columns
selected_data_normalized <- selected_data
selected_data_normalized[] <- lapply(selected_data, min_max_scaling)

# Add foreclosure_pc_2020 to the normalized dataframe
selected_data_normalized$foreclosure_pc_2020 <- min_max_scaling(pg_foreclosures_per_tract$foreclosure_pc_2020)

# Split data into training and testing sets
set.seed(123)
train_index <- createDataPartition(selected_data_normalized$foreclosure_pc_2020, p = 0.8, list = FALSE)
train_data <- selected_data_normalized[train_index, ]
test_data <- selected_data_normalized[-train_index, ]

# Define configurations to test
configurations <- list(
  list(hidden_layers = 1, neurons_per_layer = c(10), activation_function = "logistic"),
  list(hidden_layers = 2, neurons_per_layer = c(10, 5), activation_function = "tanh"),
  list(hidden_layers = 1, neurons_per_layer = c(5), activation_function = "logistic"),
  list(hidden_layers = 2, neurons_per_layer = c(5, 3), activation_function = "tanh"),
  list(hidden_layers = 3, neurons_per_layer = c(8, 6, 4), activation_function = "logistic"),
  list(hidden_layers = 3, neurons_per_layer = c(12, 8, 4), activation_function = "tanh"),
  list(hidden_layers = 4, neurons_per_layer = c(10, 8, 6, 4), activation_function = "logistic"),
  list(hidden_layers = 4, neurons_per_layer = c(12, 10, 6, 3), activation_function = "tanh"),
  list(hidden_layers = 5, neurons_per_layer = c(15, 12, 10, 8, 6), activation_function = "logistic"),
  list(hidden_layers = 5, neurons_per_layer = c(20, 15, 12, 8, 5), activation_function = "tanh")
)


# Function to build and train neural network model
train_nn_model <- function(hidden_layers, neurons_per_layer, activation_function, train_data, test_data) {
  # Build neural network model
  model <- neuralnet(
    foreclosure_pc_2020 ~ .,
    data = train_data,  # Use normalized training data
    hidden = neurons_per_layer,
    linear.output = TRUE,  # For regression tasks
    act.fct = activation_function
  )
  
  # Make predictions on test data
  predictions <- predict(model, test_data)
  
  # Calculate evaluation metrics (e.g., RMSE)
  rmse <- sqrt(mean((test_data$foreclosure_pc_2020 - predictions)^2))
  
  # Return performance results
  return(list(
    rmse = rmse,
    activation_function = activation_function,
    hidden_layers = hidden_layers,
    neurons_per_layer = neurons_per_layer
  ))
}

# Evaluate neural network models for each configuration
results <- lapply(configurations, function(config) {
  train_nn_model(config$hidden_layers, config$neurons_per_layer, config$activation_function, train_data, test_data)
})


# Report results
for (i in seq_along(results)) {
  cat("Configuration:", i, "\n")
  cat("RMSE:", results[[i]]$rmse, "\n")
  cat("Activation Function:", results[[i]]$activation_function, "\n")
  cat("Hidden Layers:", results[[i]]$hidden_layers, "\n")
  cat("Neurons per Layer:", results[[i]]$neurons_per_layer, "\n\n")
}

# Identify the best configuration based on performance metrics
best_config <- configurations[[which.min(sapply(results, function(x) x$rmse))]]

# Train the best model with the identified configuration
best_model <- train_nn_model(best_config$hidden_layers, best_config$neurons_per_layer, best_config$activation_function, train_data = train_data, test_data = test_data)
```

```{r}
# Report results
for (i in seq_along(results)) {
  cat("Configuration:", i, "\n")
  cat("RMSE:", results[[i]]$rmse, "\n")
  cat("Activation Function:", results[[i]]$activation_function, "\n")
  cat("Hidden Layers:", results[[i]]$hidden_layers, "\n")
  cat("Neurons per Layer:", results[[i]]$neurons_per_layer, "\n\n")
}

# Identify the best configuration based on performance metrics
best_config <- configurations[[which.min(sapply(results, function(x) x$rmse))]]

# Train the best model with the identified configuration
best_model <- train_nn_model(best_config$hidden_layers, best_config$neurons_per_layer, best_config$activation_function, train_data, test_data)

# Plot the neural network model
plot(best_model$model)
```




```{r}
# Filter Method for SVM
library(caret)


# Ensure 'foreclosure_pc_2020' is included in train_data
train_data <- cbind(train_data, foreclosure_pc_2020 = pg_foreclosures_per_tract[train_index, "foreclosure_pc_2020"])

# Perform correlation-based feature selection
selected_features <- findCorrelation(cor(train_data[, -which(names(train_data) == "foreclosure_pc_2020")]), cutoff = 0.8)

# Train SVM model with selected features
svm_model_filtered <- svm(foreclosure_pc_2020 ~ ., data = train_data[, selected_features], kernel = "linear")

# Evaluate the filtered SVM model
predictions_filtered <- predict(svm_model_filtered, test_data[, selected_features])
mse_filtered <- mean((test_data$foreclosure_pc_2020 - predictions_filtered)^2)
rmse_filtered <- sqrt(mse_filtered)
rsquared_filtered <- cor(predictions_filtered, test_data$foreclosure_pc_2020)^2

# Print evaluation metrics for filtered SVM model
print("Evaluation Metrics for Filtered SVM Model:")
print(paste("Mean Squared Error (MSE):", mse_filtered))
print(paste("Root Mean Squared Error (RMSE):", rmse_filtered))
print(paste("R-squared (R²):", rsquared_filtered))
```



```{r}
# Wrapper Method for Naive Bayes
library(caret)

# Perform recursive feature elimination
control <- rfeControl(functions = nbFuncs, method = "cv", number = 10)
naive_bayes_rfe <- rfe(train_data_2[, -which(names(train_data_2) == "foreclosure_quantile")], 
                        train_data_2$foreclosure_quantile, 
                        sizes = c(1:10), 
                        rfeControl = control)

# Print the results of recursive feature elimination
print(naive_bayes_rfe)
```



```{r}
# Embedded Method for Linear Regression
library(glmnet)

# Fit LASSO model
lasso_model <- cv.glmnet(as.matrix(train_data_multivariate_1[, test_variables_3]), 
                         train_data_multivariate_1$foreclosure_pc_2020, 
                         alpha = 1)

# Extract selected features from LASSO model
selected_features_lasso <- coef(lasso_model, s = "lambda.min")[-1, ]
selected_features_lasso <- names(selected_features_lasso[selected_features_lasso != 0])

# Train linear regression model with selected features
lm_model_filtered <- lm(foreclosure_pc_2020 ~ ., 
                        data = train_data_multivariate_1[, c("foreclosure_pc_2020", selected_features_lasso)])

# Evaluate the filtered linear regression model
predictions_filtered_lm <- predict(lm_model_filtered, test_data_multivariate_1[, c("foreclosure_pc_2020", selected_features_lasso)])
mse_filtered_lm <- mean((test_data_multivariate_1$foreclosure_pc_2020 - predictions_filtered_lm)^2)
rmse_filtered_lm <- sqrt(mse_filtered_lm)
rsquared_filtered_lm <- cor(predictions_filtered_lm, test_data_multivariate_1$foreclosure_pc_2020)^2

# Print evaluation metrics for filtered linear regression model
print("Evaluation Metrics for Filtered Linear Regression Model:")
print(paste("Mean Squared Error (MSE):", mse_filtered_lm))
print(paste("Root Mean Squared Error (RMSE):", rmse_filtered_lm))
print(paste("R-squared (R²):", rsquared_filtered_lm))

```

