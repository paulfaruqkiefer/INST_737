---
title: "pg_foreclosure_svm"
author: "Paul Kiefer"
date: "2024-04-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
options(scipen=999)
##install.packages("ggrepel")
##install.packages('ggthemes')
##install.packages('gplots')
#install.packages('car')
##install.packages("glmnet")
##install.packages("neuralnet")
##install.packages("mlbench")
library(tidyverse)
library(dplyr)
#Necessary for date parsing.
library(lubridate)
#Necessary for column name cleaning.
library(janitor)
#Eventually necessary for visualization
library(ggthemes)
#Necessary for Census API calls.
library(tidycensus)
#Eventually necessary for visualizations.
library(ggplot2)
library(gplots)
#Potentially necessary for cleaning.
library(ggrepel)
#Eventually necessary for visualizations.
library(tigris)
#Simple features.
library(sf)
#Eventually necessary for mapping.
library(ggmap)
#Needed for dividing into training and test sets.
library(caret)
#Needed for data pre-processing and evaluation
library(car)
#Needed for regularization
library(glmnet)
library(e1071) 
#Needed to build SVM model
library(neuralnet)
#Needed for neural networks
library(nnet)
#Needed to plot neural networks
library(mlbench)
#Needed for RFE feature selection
```

Read in our dataset: 

```{r}
pg_foreclosures_per_tract <- read_csv("datasets/pg_foreclosures_per_tract.csv", guess_max=173)
```
For the feature selection process, we also need pg_foreclosures_per_tract_log_reg:
```{r}
pg_foreclosures_per_tract_log_reg <- read_csv("datasets/pg_foreclosures_per_tract_log_reg.csv", guess_max=173)
```


First, we build an SVM using a regression approach and the continuous variable foreclosure_pc_2020.

```{r}
# Step 1: Data Preprocessing
set.seed(123)

# Select variables
independent_variables <- c(
  "avg_bed", "tract_homevalue_2020", "tract_medage_2020", "tract_medincome_2020", 
  "tract_medincome_2010", "foreclosure_pc_2010", "pct_built_2020_later", 
  "pct_built_2010_2019", "pct_built_2000_2009", "pct_built_1990_1999", 
  "pct_built_1980_1989", "pct_built_1970_1979", "pct_built_pre_1960", 
  "pct_0_bd", "pct_1_bd", "pct_2_bd", "pct_3_bd", "pct_4_more_bd", 
  "poverty_2010", "poverty_2020", "nhwhite_2010", "nhwhite_2020", 
  "mortgaged_2010", "mortgaged_2015", "mortgaged_2020", "ownoccupied_2010", 
  "ownoccupied_2015", "ownoccupied_2020", "mortgage_change_2010_2015", 
  "mortgage_change_2015_2020", "mortgage_change_2010_2020", 
  "ownoccupied_change_2010_2015", "ownoccupied_change_2015_2020", 
  "ownoccupied_change_2010_2020", "poverty_change_2010_2020", 
  "nhwhite_change_2010_2020", "medincome_change_2010_2015", 
  "medincome_change_2015_2020", "medincome_change_2010_2020", "pop_change_pct"
)
dependent_variable <- "foreclosure_pc_2020"

# Subsetting data
selected_data <- pg_foreclosures_per_tract[c(independent_variables, dependent_variable)]

# Splitting data
train_index <- sample(nrow(selected_data), 0.8 * nrow(selected_data))
train_data_1 <- selected_data[train_index, ]
test_data_1 <- selected_data[-train_index, ]

# Step 2: Model Training
svm_model <- svm(as.formula(paste(dependent_variable, "~ .")), data = train_data_1, kernel ="linear")

# Step 3: Model Evaluation
predictions <- predict(svm_model, test_data_1)

# Calculate evaluation metrics
mse <- mean((test_data_1[[dependent_variable]] - predictions)^2)
rmse <- sqrt(mse)
rsquared <- cor(predictions, test_data_1[[dependent_variable]])^2

# Print evaluation metrics
print(paste("Mean Squared Error (MSE):", mse))
print(paste("Root Mean Squared Error (RMSE):", rmse))
print(paste("R-squared (RÂ²):", rsquared))

```

To test the significance of that RSME, we can compare it to the standard deviation of the dependent variable.

```{r}
# Calculate the residuals
residuals <- test_data_1[[dependent_variable]] - predictions

# Calculate RMSE
RMSE <- sqrt(mean(residuals^2))

# Check if the RMSE is significantly different from the standard deviation
# Using a t-test
t_test_result <- t.test(test_data_1[[dependent_variable]], predictions)

# Check the p-value from the t-test
p_value <- t_test_result$p.value

# Check if p-value is less than a significance level (e.g., 0.05)
significance_level <- 0.05
if (p_value < significance_level) {
  print("RMSE is statistically significant.")
} else {
  print("RMSE is not statistically significant.")
}

print(p_value)
```
In other words, the RSME of the first SVM is not so substantial that the difference between the predicted and actual values has a reasonable chance of occurring due to random chance alone. 

Next, we create a column called foreclosure_hi_med_low to the dataframe and test a version of the SVM that uses a classifier rather than a regression. 

```{r}
# Add a new column 'foreclosure_hi_med_low' to the dataframe
pg_foreclosures_per_tract$foreclosure_hi_med_low <- cut(pg_foreclosures_per_tract$foreclosure_pc_2020,
                                                        breaks = quantile(pg_foreclosures_per_tract$foreclosure_pc_2020, probs = c(0, 1/3, 2/3, 1)),
                                                        labels = c(1, 2, 3),
                                                        include.lowest = TRUE)

# Convert the new column to factor
pg_foreclosures_per_tract$foreclosure_hi_med_low <- as.factor(pg_foreclosures_per_tract$foreclosure_hi_med_low)

# Select the list of independent variables
independent_variables <- c(
  "avg_bed", "tract_homevalue_2020", "tract_medage_2020", "tract_medincome_2020", 
  "tract_medincome_2010", "foreclosure_pc_2010", "pct_built_2020_later", 
  "pct_built_2010_2019", "pct_built_2000_2009", "pct_built_1990_1999", 
  "pct_built_1980_1989", "pct_built_1970_1979", "pct_built_pre_1960", 
  "pct_0_bd", "pct_1_bd", "pct_2_bd", "pct_3_bd", "pct_4_more_bd", 
  "poverty_2010", "poverty_2020", "nhwhite_2010", "nhwhite_2020", 
  "mortgaged_2010", "mortgaged_2015", "mortgaged_2020", "ownoccupied_2010", 
  "ownoccupied_2015", "ownoccupied_2020", "mortgage_change_2010_2015", 
  "mortgage_change_2015_2020", "mortgage_change_2010_2020", 
  "ownoccupied_change_2010_2015", "ownoccupied_change_2015_2020", 
  "ownoccupied_change_2010_2020", "poverty_change_2010_2020", 
  "nhwhite_change_2010_2020", "medincome_change_2010_2015", 
  "medincome_change_2015_2020", "medincome_change_2010_2020", "pop_change_pct"
)

# Train-test split
set.seed(123)
train_index <- createDataPartition(pg_foreclosures_per_tract$foreclosure_hi_med_low, p = 0.8, list = FALSE)
train_data_2 <- pg_foreclosures_per_tract[train_index, ]
test_data_2 <- pg_foreclosures_per_tract[-train_index, ]

# Subsetting data with only selected variables
selected_train_data_2 <- train_data_2[c(independent_variables, "foreclosure_hi_med_low")]
selected_test_data_2 <- test_data_2[c(independent_variables, "foreclosure_hi_med_low")]

# Train SVM model for classification
svm_model_classification <- svm(foreclosure_hi_med_low ~ ., data = selected_train_data_2, kernel = "linear")

# Predictions on test set
predictions_classification <- predict(svm_model_classification, selected_test_data_2)

# Evaluate classification performance
conf_matrix <- confusionMatrix(predictions_classification, selected_test_data_2$foreclosure_hi_med_low)

# Calculate precision, recall, specificity, and F1 measure for each class
precision <- diag(conf_matrix$table) / colSums(conf_matrix$table)
recall <- diag(conf_matrix$table) / rowSums(conf_matrix$table)
specificity <- diag(conf_matrix$table[2:3, 2:3]) / colSums(conf_matrix$table[2:3, 2:3])
f1_measure <- 2 * (precision * recall) / (precision + recall)

# Print the confusion matrix
print(conf_matrix)

# Print precision, recall, specificity, and F1 measure for each class
cat("\nPrecision:\n", precision, "\n")
cat("Recall:\n", recall, "\n")
cat("Specificity:\n", specificity, "\n")
cat("F1 Measure:\n", f1_measure, "\n")


```
**NON-LINEAR KERNELS**

We will test both the regression and classification models with RBF and polynomial kernels.

First, the regression SVM with an RBF kernel:

```{r}
# Train SVM model with RBF kernel for regression
svm_model_rbf_regression <- svm(foreclosure_pc_2020 ~ ., data = train_data_1, kernel = "radial")

# Predictions on test set
predictions_rbf_regression <- predict(svm_model_rbf_regression, test_data_1)

# Calculate evaluation metrics (RMSE for regression)
rmse_rbf_regression <- sqrt(mean((test_data_1$foreclosure_pc_2020 - predictions_rbf_regression)^2))
print(paste("Root Mean Squared Error (RMSE) for RBF Kernel (Regression):", rmse_rbf_regression))
```

This RMSE is slightly larger than the RSME of the model with a linear kernel. 

To test the significance of that RMSE, we compare it to the standard deviation of foreclosure_pc_2020. 

```{r}
# Predictions on test set
predictions_rbf_regression <- predict(svm_model_rbf_regression, test_data_1)

# Calculate the residuals
residuals_rbf_regression <- test_data_1$foreclosure_pc_2020 - predictions_rbf_regression

# Calculate RMSE
rmse_rbf_regression <- sqrt(mean(residuals_rbf_regression^2))
print(paste("Root Mean Squared Error (RMSE) for RBF Kernel (Regression):", rmse_rbf_regression))

# Check if the RMSE is significantly different from the standard deviation
# Using a t-test
t_test_result <- t.test(test_data_1$foreclosure_pc_2020, predictions_rbf_regression)

# Check the p-value from the t-test
p_value <- t_test_result$p.value

# Check if p-value is less than a significance level (e.g., 0.05)
significance_level <- 0.05
if (p_value < significance_level) {
  print("RMSE is statistically significant.")
} else {
  print("RMSE is not statistically significant.")
}

print(p_value)
```

While the comparison does not provide evidence to disprove the null hypothesis, it is still not a stronger model than the model with a linear kernel.

Next, the regression SVM Model with a polynomial kernel. 

```{r}
# Train SVM model with Polynomial kernel for regression
svm_model_poly <- svm(foreclosure_pc_2020 ~ ., data = train_data_1, kernel = "polynomial")

# Predictions on test set
predictions_poly <- predict(svm_model_poly, test_data_1)

# Calculate evaluation metrics (RMSE for regression)
rmse_poly <- sqrt(mean((test_data_1$foreclosure_pc_2020 - predictions_poly)^2))
print(paste("Root Mean Squared Error (RMSE) for Polynomial Kernel:", rmse_poly))
```

This RMSE is also slightly higher than the RMSE of the model with a linear kernel. 

We can check the significance of that RMSE by comparing it to the standard deviation and range of foreclosure_pc_2020. 
```{r}
# Train SVM model with Polynomial kernel for regression
svm_model_poly <- svm(foreclosure_pc_2020 ~ ., data = train_data_1, kernel = "polynomial")

# Predictions on test set
predictions_poly <- predict(svm_model_poly, test_data_1)

# Calculate evaluation metrics (RMSE for regression)
rmse_poly <- sqrt(mean((test_data_1$foreclosure_pc_2020 - predictions_poly)^2))
print(paste("Root Mean Squared Error (RMSE) for Polynomial Kernel:", rmse_poly))

# Check if the RMSE is significantly different from the standard deviation
# Using a t-test
t_test_result <- t.test(test_data_1$foreclosure_pc_2020, predictions_poly)

# Check the p-value from the t-test
p_value <- t_test_result$p.value

# Check if p-value is less than a significance level (e.g., 0.05)
significance_level <- 0.05
if (p_value < significance_level) {
  print("RMSE is statistically significant.")
} else {
  print("RMSE is not statistically significant.")
}

print(p_value)
```
While the comparison does not provide evidence to disprove the null hypothesis, it is still not a stronger model than both the model with a linear kernel and the model with the RBF kernel.

Next, we apply both the RBF and polynomial kernels to the classification SVM.

SVM Classification with RBF Kernel
```{r}
# Train-test split
set.seed(123)
train_index <- createDataPartition(pg_foreclosures_per_tract$foreclosure_hi_med_low, p = 0.8, list = FALSE)
train_data_2 <- pg_foreclosures_per_tract[train_index, ]
test_data_2 <- pg_foreclosures_per_tract[-train_index, ]

# Subsetting data with only selected variables
selected_train_data_2 <- train_data_2[c(independent_variables, "foreclosure_hi_med_low")]
selected_test_data_2 <- test_data_2[c(independent_variables, "foreclosure_hi_med_low")]

# Train SVM model for classification with RBF kernel
svm_model_classification_rbf <- svm(foreclosure_hi_med_low ~ ., data = selected_train_data_2, kernel = "radial")

# Predictions on test set
predictions_classification_rbf <- predict(svm_model_classification_rbf, selected_test_data_2)

# Evaluate classification performance
conf_matrix_rbf <- confusionMatrix(predictions_classification_rbf, selected_test_data_2$foreclosure_hi_med_low)

# Calculate precision, recall, specificity, and F1 measure for each class
precision_rbf <- diag(conf_matrix_rbf$table) / colSums(conf_matrix_rbf$table)
recall_rbf <- diag(conf_matrix_rbf$table) / rowSums(conf_matrix_rbf$table)
specificity_rbf <- diag(conf_matrix_rbf$table[2:3, 2:3]) / colSums(conf_matrix_rbf$table[2:3, 2:3])
f1_measure_rbf <- 2 * (precision_rbf * recall_rbf) / (precision_rbf + recall_rbf)

# Print the confusion matrix
print(conf_matrix_rbf)

# Print precision, recall, specificity, and F1 measure for each class
cat("\nPrecision:\n", precision_rbf, "\n")
cat("Recall:\n", recall_rbf, "\n")
cat("Specificity:\n", specificity_rbf, "\n")
cat("F1 Measure:\n", f1_measure_rbf, "\n")

```
Overall, this model is less accurate than the model with the linear kernel.

SVM classification model with polynomial kernel;
```{r}
# Train SVM model for classification with polynomial kernel
svm_model_classification_poly <- svm(foreclosure_hi_med_low ~ ., data = selected_train_data_2, kernel = "polynomial")

# Predictions on test set
predictions_classification_poly <- predict(svm_model_classification_poly, selected_test_data_2)

# Evaluate classification performance
conf_matrix_poly <- confusionMatrix(predictions_classification_poly, selected_test_data_2$foreclosure_hi_med_low)

# Calculate precision, recall, specificity, and F1 measure for each class
precision_poly <- diag(conf_matrix_poly$table) / colSums(conf_matrix_poly$table)
recall_poly <- diag(conf_matrix_poly$table) / rowSums(conf_matrix_poly$table)
specificity_poly <- diag(conf_matrix_poly$table[2:3, 2:3]) / colSums(conf_matrix_poly$table[2:3, 2:3])
f1_measure_poly <- 2 * (precision_poly * recall_poly) / (precision_poly + recall_poly)

# Print the confusion matrix
print(conf_matrix_poly)

# Print precision, recall, specificity, and F1 measure for each class
cat("\nPrecision:\n", precision_poly, "\n")
cat("Recall:\n", recall_poly, "\n")
cat("Specificity:\n", specificity_poly, "\n")
cat("F1 Measure:\n", f1_measure_poly, "\n")

```
While this model is slightly more accurate than the model with the RBF kernel, it is less accurate in all quantiles than the model with the linear kernel. 



**NEURAL NETWORKS**

We test Neural Networks with multiple configurations (i.e. activaion functions, number of hidden layers, numbers of neurons per layer):
  
```{r}
# Select the list of independent variables and the dependent variable
independent_variables <- c(
  "avg_bed", "tract_homevalue_2020", "tract_medage_2020", "tract_medincome_2020", 
  "tract_medincome_2010", "foreclosure_pc_2010", "pct_built_2020_later", 
  "pct_built_2010_2019", "pct_built_2000_2009", "pct_built_1990_1999", 
  "pct_built_1980_1989", "pct_built_1970_1979", "pct_built_pre_1960", 
  "pct_0_bd", "pct_1_bd", "pct_2_bd", "pct_3_bd", "pct_4_more_bd", 
  "poverty_2010", "poverty_2020", "nhwhite_2010", "nhwhite_2020", 
  "mortgaged_2010", "mortgaged_2015", "mortgaged_2020", "ownoccupied_2010", 
  "ownoccupied_2015", "ownoccupied_2020", "mortgage_change_2010_2015", 
  "mortgage_change_2015_2020", "mortgage_change_2010_2020", 
  "ownoccupied_change_2010_2015", "ownoccupied_change_2015_2020", 
  "ownoccupied_change_2010_2020", "poverty_change_2010_2020", 
  "nhwhite_change_2010_2020", "medincome_change_2010_2015", 
  "medincome_change_2015_2020", "medincome_change_2010_2020", "pop_change_pct"
)

# Scale from 0-1
min_max_scaling <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}

# Extract the selected columns from the dataframe
selected_data <- pg_foreclosures_per_tract[independent_variables]S

# Normalize the selected columns
selected_data_normalized <- selected_data
selected_data_normalized[] <- lapply(selected_data, min_max_scaling)

# Add foreclosure_pc_2020 to the normalized dataframe
selected_data_normalized$foreclosure_pc_2020 <- min_max_scaling(pg_foreclosures_per_tract$foreclosure_pc_2020)

# Split data into training and testing sets
set.seed(123)
train_index <- createDataPartition(selected_data_normalized$foreclosure_pc_2020, p = 0.8, list = FALSE)
train_data_4 <- selected_data_normalized[train_index, ]
test_data_4 <- selected_data_normalized[-train_index, ]

# Define configurations to test
configurations <- list(
  list(hidden_layers = 1, neurons_per_layer = c(10), activation_function = "logistic"),
  list(hidden_layers = 2, neurons_per_layer = c(10, 5), activation_function = "tanh"),
  list(hidden_layers = 1, neurons_per_layer = c(5), activation_function = "logistic"),
  list(hidden_layers = 2, neurons_per_layer = c(5, 3), activation_function = "tanh"),
  list(hidden_layers = 3, neurons_per_layer = c(8, 6, 4), activation_function = "logistic"),
  list(hidden_layers = 3, neurons_per_layer = c(12, 8, 4), activation_function = "tanh"),
  list(hidden_layers = 4, neurons_per_layer = c(10, 8, 6, 4), activation_function = "logistic"),
  list(hidden_layers = 4, neurons_per_layer = c(12, 10, 6, 3), activation_function = "tanh"),
  list(hidden_layers = 5, neurons_per_layer = c(15, 12, 10, 8, 6), activation_function = "logistic"),
  list(hidden_layers = 5, neurons_per_layer = c(20, 15, 12, 8, 5), activation_function = "tanh")
)


# Function to build and train neural network model
train_nn_model <- function(hidden_layers, neurons_per_layer, activation_function, train_data_4, test_data_4) {
  # Build neural network model
  model <- neuralnet(
    foreclosure_pc_2020 ~ .,
    data = train_data_4,  # Use normalized training data
    hidden = neurons_per_layer,
    linear.output = TRUE,  # For regression tasks
    act.fct = activation_function
  )
  
  # Make predictions on test data
  predictions <- predict(model, test_data_4)
  
  # Calculate evaluation metrics (e.g., RMSE)
  rmse <- sqrt(mean((test_data_4$foreclosure_pc_2020 - predictions)^2))
  
  # Return performance results
  return(list(
    rmse = rmse,
    activation_function = activation_function,
    hidden_layers = hidden_layers,
    neurons_per_layer = neurons_per_layer,
    model = model
  ))
}

# Evaluate neural network models for each configuration
results <- lapply(configurations, function(config) {
  train_nn_model(config$hidden_layers, config$neurons_per_layer, config$activation_function, train_data_4, test_data_4)
})


# Report results
for (i in seq_along(results)) {
  cat("Configuration:", i, "\n")
  cat("RMSE:", results[[i]]$rmse, "\n")
  cat("Activation Function:", results[[i]]$activation_function, "\n")
  cat("Hidden Layers:", results[[i]]$hidden_layers, "\n")
  cat("Neurons per Layer:", results[[i]]$neurons_per_layer, "\n\n")
}

# Identify the best configuration based on performance metrics
best_config <- configurations[[which.min(sapply(results, function(x) x$rmse))]]

# Train the best model with the identified configuration
best_model <- train_nn_model(best_config$hidden_layers, best_config$neurons_per_layer, best_config$activation_function, train_data_4 = train_data_4, test_data_4 = test_data_4)
```
The best-performing NN is configuration 7, plotted here:

```{r}
plot(best_model$model, cex = 0.8) 
```



Feature selection:

SVM

```{r}
# Step 1: Data Preprocessing
set.seed(123)

# Select variables
independent_variables <- c(
  "avg_bed", "tract_homevalue_2020", "tract_medage_2020", "tract_medincome_2020", 
  "tract_medincome_2010", "foreclosure_pc_2010", "pct_built_2020_later", 
  "pct_built_2010_2019", "pct_built_2000_2009", "pct_built_1990_1999", 
  "pct_built_1980_1989", "pct_built_1970_1979", "pct_built_pre_1960", 
  "pct_0_bd", "pct_1_bd", "pct_2_bd", "pct_3_bd", "pct_4_more_bd", 
  "poverty_2010", "poverty_2020", "nhwhite_2010", "nhwhite_2020", 
  "mortgaged_2010", "mortgaged_2015", "mortgaged_2020", "ownoccupied_2010", 
  "ownoccupied_2015", "ownoccupied_2020", "mortgage_change_2010_2015", 
  "mortgage_change_2015_2020", "mortgage_change_2010_2020", 
  "ownoccupied_change_2010_2015", "ownoccupied_change_2015_2020", 
  "ownoccupied_change_2010_2020", "poverty_change_2010_2020", 
  "nhwhite_change_2010_2020", "medincome_change_2010_2015", 
  "medincome_change_2015_2020", "medincome_change_2010_2020", "pop_change_pct"
)
dependent_variable <- "foreclosure_pc_2020"

# Subsetting data
selected_data <- pg_foreclosures_per_tract[c(independent_variables, dependent_variable)]

# Splitting data
train_index <- sample(nrow(selected_data), 0.8 * nrow(selected_data))
train_data_1 <- selected_data[train_index, ]
test_data_1 <- selected_data[-train_index, ]

# Step 2: Model Training
base_model <- lm(foreclosure_pc_2020 ~ 1, data = train_data_1) # Intercept-only model
full_model <- lm(foreclosure_pc_2020 ~ ., data = train_data_1) # Full model

# Step 3: Perform step-wise algorithm
step_model <- step(base_model, scope = list(lower = base_model, upper = full_model), direction = "both", trace = 0)

# Get selected variables
selected_variables_2 <- attr(terms(step_model), "term.labels")

# Step 4: Model Evaluation
predictions <- predict(step_model, newdata = test_data_1)

# Calculate evaluation metrics for base model
base_mse <- mean((test_data_1[[dependent_variable]] - predict(base_model, newdata = test_data_1))^2)
base_rmse <- sqrt(base_mse)
base_rsquared <- cor(predict(base_model, newdata = test_data_1), test_data_1[[dependent_variable]])^2

# Calculate evaluation metrics for final model
final_mse <- mean((test_data_1[[dependent_variable]] - predictions)^2)
final_rmse <- sqrt(final_mse)
final_rsquared <- cor(predictions, test_data_1[[dependent_variable]])^2

# Print performance comparison
print("Performance comparison:")
print(paste("Base Model - Mean Squared Error (MSE):", base_mse))
print(paste("Final Model - Mean Squared Error (MSE):", final_mse))
print(paste("Improvement in MSE:", base_mse - final_mse))
print(paste("Base Model - Root Mean Squared Error (RMSE):", base_rmse))
print(paste("Final Model - Root Mean Squared Error (RMSE):", final_rmse))
print(paste("Improvement in RMSE:", base_rmse - final_rmse))

# Print R-squared comparison if applicable
if (!is.na(base_rsquared)) {
  print(paste("Base Model - R-squared (RÂ²):", base_rsquared))
}
print(paste("Final Model - R-squared (RÂ²):", final_rsquared))
if (!is.na(base_rsquared)) {
  print(paste("Improvement in R-squared (RÂ²):", final_rsquared - base_rsquared))
} else {
  print("R-squared comparison not applicable for the base model.")
}

# Print selected variables
print("Selected variables in the final model:")
print(selected_variables_2)

```


Naive Bayes
```{r}
# Convert foreclosure_quantile to a factor with ordered levels
pg_foreclosures_per_tract_log_reg$foreclosure_quantile <- factor(
  pg_foreclosures_per_tract_log_reg$foreclosure_quantile,
  levels = 1:5,
  ordered = TRUE
)

set.seed(123) # For reproducibility
test_percent <- 0.2
indices <- sample(1:nrow(pg_foreclosures_per_tract_log_reg), 
                  size = round(test_percent * nrow(pg_foreclosures_per_tract_log_reg)))

train_data_2 <- pg_foreclosures_per_tract_log_reg[-indices, ]
test_data_2 <- pg_foreclosures_per_tract_log_reg[indices, ]

# Extracting independent variables
independent_variables <- c(
  "nhwhite_2020", "foreclosure_pc_2010", "tract_medage_2020", 
  "poverty_2010", "medincome_change_2010_2020", "avg_bed", 
  "mortgaged_2010", "pct_1_bd", "pct_built_pre_1960", 
  "pct_built_2000_2009", "mortgage_change_2010_2015",
  "pop_change_pct"
)

# Fit logistic regression model with stepwise feature selection
stepwise_model <- step(
  glm(foreclosure_quantile ~ ., 
      data = train_data_2[, c(independent_variables, "foreclosure_quantile")],
      family = binomial),
  direction = "both"
)

# Extract selected variables
selected_variables <- attr(terms(stepwise_model), "term.labels")

# Fit Naive Bayes model with selected variables
selected_naive_bayes_model <- naiveBayes(
  formula = as.formula(paste("foreclosure_quantile ~", paste(selected_variables, collapse = " + "))),
  data = train_data_2
)

# Predict using the Naive Bayes model
predictions <- predict(selected_naive_bayes_model, newdata = test_data_2)

# Create the confusion matrix
confusion_matrix <- confusionMatrix(predictions, test_data_2$foreclosure_quantile)

# Print the confusion matrix
print(confusion_matrix)

```



```{r}
# Define test variables
test_variables_3 <- c("mortgaged_2010", "tract_homevalue_2020", "tract_medage_2020", "tract_medincome_2020", 
                      "foreclosure_pc_2010", "pct_built_2000_2009", "poverty_2010", "nhwhite_2020", 
                      "mortgage_change_2010_2020", "poverty_change_2010_2020", "nhwhite_change_2010_2020",
                      "medincome_change_2010_2015", "medincome_change_2015_2020", "medincome_change_2010_2020", 
                      "pop_change_pct")

# Split the data into training and testing sets
set.seed(123) # for reproducibility
train_indices <- createDataPartition(pg_foreclosures_per_tract$foreclosure_pc_2020, p = 0.8, list = FALSE)
train_data_6 <- pg_foreclosures_per_tract[train_indices, ]
test_data_6 <- pg_foreclosures_per_tract[-train_indices, ]

# Define control parameters for RFE
ctrl <- rfeControl(functions = lmFuncs, method = "cv", number = 10)

# Perform RFE on new training data excluding tract_number
lm_model_rfe <- rfe(x = train_data_6[, test_variables_3], 
                    y = train_data_6$foreclosure_pc_2020, 
                    sizes = c(1:15), 
                    rfeControl = ctrl)

# Extract the selected features
selected_features <- predictors(lm_model_rfe)

# Train the linear regression model on the new training data with selected features
lm_model_selected <- lm(foreclosure_pc_2020 ~ . - 1, data = train_data_6[, c("foreclosure_pc_2020", selected_features)])

# Use the trained model to predict on the testing data with selected features
predicted_values_selected <- predict(lm_model_selected, newdata = test_data_6[, c(selected_features)])

# Calculate the correlation between the predicted and real values with selected features
correlation_selected <- cor(predicted_values_selected, test_data_6$foreclosure_pc_2020)

# Calculate the mean squared error between the predicted and real values with selected features
mse_selected <- mean((predicted_values_selected - test_data_6$foreclosure_pc_2020)^2)

# Obtain coefficients for each selected feature
coefficients_selected <- coef(lm_model_selected)
print(coefficients_selected)

# Print the selected features, correlation, and mean squared error
cat("Selected features:", selected_features, "\n")
cat("Correlation between predicted and real values with selected features:", correlation_selected, "\n")
cat("Mean Squared Error with selected features:", mse_selected, "\n")

```
```{r}
# Define independent variables
independent_variables <- c(
  "avg_bed", "tract_homevalue_2020", "tract_medage_2020", "tract_medincome_2020", 
  "tract_medincome_2010", "foreclosure_pc_2010", "pct_built_2020_later", 
  "pct_built_2010_2019", "pct_built_2000_2009", "pct_built_1990_1999", 
  "pct_built_1980_1989", "pct_built_1970_1979", "pct_built_pre_1960", 
  "pct_0_bd", "pct_1_bd", "pct_2_bd", "pct_3_bd", "pct_4_more_bd", 
  "poverty_2010", "poverty_2020", "nhwhite_2010", "nhwhite_2020", 
  "mortgaged_2010", "mortgaged_2015", "mortgaged_2020", "ownoccupied_2010", 
  "ownoccupied_2015", "ownoccupied_2020", "mortgage_change_2010_2015", 
  "mortgage_change_2015_2020", "mortgage_change_2010_2020", 
  "ownoccupied_change_2010_2015", "ownoccupied_change_2015_2020", 
  "ownoccupied_change_2010_2020", "poverty_change_2010_2020", 
  "nhwhite_change_2010_2020", "medincome_change_2010_2015", 
  "medincome_change_2015_2020", "medincome_change_2010_2020", "pop_change_pct"
)

# Split the data into training and testing sets
set.seed(123) # for reproducibility
train_indices <- createDataPartition(pg_foreclosures_per_tract$foreclosure_pc_2020, p = 0.8, list = FALSE)
train_data_7 <- pg_foreclosures_per_tract[train_indices, ]
test_data_7 <- pg_foreclosures_per_tract[-train_indices, ]

# Define control parameters for RFE
ctrl <- rfeControl(functions = lmFuncs, method = "cv", number = 10)

# Perform RFE on new training data using independent_variables
lm_model_rfe <- rfe(x = train_data_7[, independent_variables], 
                    y = train_data_7$foreclosure_pc_2020, 
                    sizes = c(1:15), 
                    rfeControl = ctrl)

# Extract the selected features
selected_features <- predictors(lm_model_rfe)

# Train the linear regression model on the new training data with selected features
lm_model_selected <- lm(foreclosure_pc_2020 ~ . - 1, data = train_data_7[, c("foreclosure_pc_2020", selected_features)])

# Use the trained model to predict on the testing data with selected features
predicted_values_selected <- predict(lm_model_selected, newdata = test_data_7[, c(selected_features)])

# Calculate the correlation between the predicted and real values with selected features
correlation_selected <- cor(predicted_values_selected, test_data_7$foreclosure_pc_2020)

# Calculate the mean squared error between the predicted and real values with selected features
mse_selected <- mean((predicted_values_selected - test_data_7$foreclosure_pc_2020)^2)

# Obtain coefficients for each selected feature
coefficients_selected <- coef(lm_model_selected)
print(coefficients_selected)

# Print the selected features, correlation, and mean squared error
cat("Selected features:", selected_features, "\n")
cat("Correlation between predicted and real values with selected features:", correlation_selected, "\n")
cat("Mean Squared Error with selected features:", mse_selected, "\n")

```

